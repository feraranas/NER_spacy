title: "Example project of creating a novel nlp component to do relation extraction from scratch."
description: "This example project shows how to implement a spaCy component with a custom Machine Learning model, how to train it with and without a transformer, and how to apply it on an evaluation dataset."

# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  annotations: "assets/golden.jsonl"
  tok2vec_config: "configs/rel_tok2vec.cfg"
  trf_config: "configs/ner_trf.cfg"
  train_file: "data/train.spacy"
  dev_file: "data/dev.spacy"
  test_file: "data/test.spacy"
  predict_file: "data/predict.spacy"
  trained_model: "training/model-best"
  version: "0.0.0"
  ner_rel_skill_model: "ner_rel_skills_model-0.0.0"
  database: "occ_skills"
  eval_split: 0.25
  gpu_id: -1

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["scripts", "configs", "assets", "data", "training"]

# Assets that should be downloaded or available in the directory. You can replace
# this with your own input data.
assets:
    - dest: ${vars.annotations}
      description: "Gold-standard REL annotations created with Prodigy"

workflows:
  all:
    - data
    - train_cpu
    - evaluate
  all_gpu:
    - data
    - train_gpu
    - evaluate

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: prep
    help: "Install the base models."
    script:
      - "python -m spacy download en_core_web_md"
      - "pip install assets/${vars.ner_rel_skill_model}.tar.gz --no-deps"
      
  - name: assemble
    help: "Build two versions of the combined pipelines from configs."
    script:
      - "python -m spacy assemble ${vars.tok2vec_config} ${vars.trained_model}"
    deps:
      - ${vars.tok2vec_config}
      - ${vars.trained_model}
    outputs:
      - ${vars.trained_model}

  - name: package
    help: "Package the pipelines so they can be installed."
    script: 
      - "python -m spacy package ${vars.trained_model} packages --name ner_rel_skill_model --version ${vars.version} --force"
    deps:
      - ${vars.trained_model}
    outputs_no_cache:
      - "packages/en_ner_rel_skill_first-${vars.version}/dist/en_ner_rel_skill_first-${vars.version}.tar.gz"

  - name: "data"
    help: "Parse the gold-standard annotations from the Prodigy annotations."
    script:
      - "python ./scripts/parse_data_generic.py ${vars.annotations} ${vars.train_file} ${vars.dev_file} ${vars.test_file}"
    deps:
      - ${vars.annotations}
    outputs:
      - ${vars.train_file}
      - ${vars.dev_file}
      - ${vars.test_file}

  - name: "train_cpu"
    help: "Train the REL model on the CPU and evaluate on the dev corpus."
    script:
      - "python -m spacy train ${vars.tok2vec_config} --output training --paths.train ${vars.train_file} --paths.dev ${vars.dev_file} -c ./scripts/custom_functions.py"
      # The following line adds --paths.vectors en_core_web_md to the training command line: TODO: check how this helps.
      # - "python -m spacy train ${vars.tok2vec_config} --output training --paths.train ${vars.train_file} --paths.dev ${vars.dev_file} --paths.vectors en_core_web_md -c ./scripts/custom_functions.py"
    deps:
      - ${vars.train_file}
      - ${vars.dev_file}
    outputs:
      - ${vars.trained_model}

  - name: "train_gpu"
    help: "Train the REL model with a Transformer on a GPU and evaluate on the dev corpus."
    script:
      - "python -m spacy train ${vars.trf_config} --output training --paths.train ${vars.train_file} --paths.dev ${vars.dev_file} -c ./scripts/custom_functions.py --gpu-id 0"
    deps:
      - ${vars.train_file}
      - ${vars.dev_file}
    outputs:
      - ${vars.trained_model}

  - name: "evaluate"
    help: "Apply the best model to new, unseen text, and measure accuracy at different thresholds."
    script:
      - "python ./scripts/evaluate.py ${vars.trained_model} ${vars.test_file} False"
    deps:
      - ${vars.trained_model}
      - ${vars.test_file}

  - name: "clean"
    help: "Remove intermediate files to start data preparation and training from a clean slate."
    script:
      - "rm -rf data/*"
      - "rm -rf training/*"

  - name: "train_spancat"
    help: "Train a spancat model."
    script:
      - "python -m prodigy train ./training --spancat ${vars.annotations} --eval-split ${vars.eval_split} --gpu-id ${vars.gpu_id}"
    outputs:
      - "training/model-best"
  
  - name: check
    help: "Use the pipeline interactively using Streamlit"
    script:
      - "streamlit run scripts/check.py ${vars.trained_model} \"The Security Operations Manager plans and oversees monitoring and maintenance of security operations and provides direction and leadership to internal resources. He/She provides expertise on security technologies and innovative security concepts and works toward enhancing the resilience of security operations. He coordinates ongoing reviews of existing security programs, protocols and planned upgrades. He establishes escalation processes for security incidents and develops contingency plans and disaster recovery procedures. He focuses on policy implementation and control. He is familiar with cyber security standards, protocols and frameworks, and ensures the organisations compliance with the Cyber Security Act 2018. He is knowledgeable in using various cyber security monitoring and testing tools and techniques. The Security Operations Manager is diligent and watchful in monitoring security operations, systems and activities. He is also a confident leader who develops plans and solutions to address security incidents and also one who has a passion for engaging and developing others in his team.\""
    deps:
      - pipelines/drugs_first
      - pipelines/drugs_second